{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import src.data_manager as data_manager\n",
    "import src.gfdl as gfdl\n",
    "import src.util as util\n",
    "import src.datelabel as datelabel\n",
    "import src.shared_diagnostic as shared_diagnostic\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = util.read_yaml('./src/config.yml')\n",
    "cmdline_args = {'CODE_ROOT':os.getcwd()}\n",
    "test_dir = '/archive/oar.gfdl.cmip6/CM4/warsaw_201710_om4_v1.0.1/CM4_historical/gfdl.ncrc4-intel16-prod-openmp/pp'\n",
    "test_case = {\n",
    "    'CASENAME': 'CM4_historical', 'model': 'CM4', \n",
    "     'variable_convention': 'CMIP',\n",
    "    'FIRSTYR': 1970, 'LASTYR': 1989,\n",
    "    'pod_list': []\n",
    "}\n",
    "test_varlist = [\n",
    "    {'var_name':'rlut', 'freq':'day'},\n",
    "    {'var_name':'pr', 'freq':'day'},\n",
    "    {'var_name':'omega500', 'freq':'day'},\n",
    "    {'var_name':'u200', 'freq':'day'},\n",
    "    {'var_name':'u850', 'freq':'day'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(data_manager)\n",
    "reload(gfdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(gfdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet({'CF_name': 'pr_var', 'requirement': 'required', 'name': 'pr_var', 'date_freq': DateFrequency('1da'), 'required': True, 'date_range': DateRange('1970-1989'), 'remote_resource': None, 'var_name': 'pr_var', 'name_in_model': 'pr', 'units': None, 'freq': 'day', 'local_resource': '/local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc', 'alternates': []})\n"
     ]
    }
   ],
   "source": [
    "config = util.parse_mdtf_args(None, cmdline_args, default_args)\n",
    "util.PathManager(config['paths'])\n",
    "dm = gfdl.GfdlppDataManager(test_dir, test_case)\n",
    "pod = shared_diagnostic.Diagnostic('MJO_prop_amp')\n",
    "dm.pods = [pod]\n",
    "for pod in dm.pods:\n",
    "    dm._setup_pod(pod)\n",
    "ds = dm.pods[0].varlist[0].copy()\n",
    "print ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.query_dataset(ds)\n",
    "print ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm._query_dataset_and_alts(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pod in dm.pods:\n",
    "    new_varlist = []\n",
    "    for var in pod.varlist:\n",
    "        try:\n",
    "            new_varlist.extend(dm._query_dataset_and_alts(var))\n",
    "        except DataQueryFailure:\n",
    "            print \"Data query failed on pod {}\".format(pod.name)\n",
    "            raise\n",
    "    pod.varlist = new_varlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atmos_cmip_2deg_daily_3D/ts/daily/5yr/atmos_cmip_2deg_daily_3D.19800101-19841231.hus.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19800101-19841231.prw.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19700101-19741231.prw.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc\n",
      "atmos_cmip_2deg_daily_3D/ts/daily/5yr/atmos_cmip_2deg_daily_3D.19750101-19791231.hus.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19850101-19891231.prw.nc\n",
      "atmos_cmip_2deg_daily_3D/ts/daily/5yr/atmos_cmip_2deg_daily_3D.19700101-19741231.hus.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19750101-19791231.prw.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc\n",
      "atmos_cmip_2deg_daily_3D/ts/daily/5yr/atmos_cmip_2deg_daily_3D.19850101-19891231.hus.nc\n",
      "atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc\n"
     ]
    }
   ],
   "source": [
    "files = dm.plan_data_fetching()\n",
    "for f in files:\n",
    "    print f.remote_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gcp', '--sync', 'gfdl:/archive/oar.gfdl.cmip6/CM4/warsaw_201710_om4_v1.0.1/CM4_historical/gfdl.ncrc4-intel16-prod-openmp/pp/atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc', 'gfdl:/net2/Thomas.Jackson/tmp/MDTF_temp_-0x2d0ee0fca7b03bba/']\n",
      "['gcp', '--sync', 'gfdl:/archive/oar.gfdl.cmip6/CM4/warsaw_201710_om4_v1.0.1/CM4_historical/gfdl.ncrc4-intel16-prod-openmp/pp/atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc', 'gfdl:/net2/Thomas.Jackson/tmp/MDTF_temp_-0x2d0ee0fca7b03bba/']\n",
      "['gcp', '--sync', 'gfdl:/archive/oar.gfdl.cmip6/CM4/warsaw_201710_om4_v1.0.1/CM4_historical/gfdl.ncrc4-intel16-prod-openmp/pp/atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc', 'gfdl:/net2/Thomas.Jackson/tmp/MDTF_temp_-0x2d0ee0fca7b03bba/']\n",
      "['gcp', '--sync', 'gfdl:/archive/oar.gfdl.cmip6/CM4/warsaw_201710_om4_v1.0.1/CM4_historical/gfdl.ncrc4-intel16-prod-openmp/pp/atmos_cmip_2deg_daily_2D/ts/daily/5yr/atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc', 'gfdl:/net2/Thomas.Jackson/tmp/MDTF_temp_-0x2d0ee0fca7b03bba/']\n",
      "['atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc', 'atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc', 'atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc', 'atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc']\n",
      "['ncrcat', 'atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc', 'atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc', 'atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc', 'atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc', '/local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc']\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'ncrcat atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ba33fac4d128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/local2/home/MDTF/MDTF-diagnostics/src/gfdl.pyc\u001b[0m in \u001b[0;36mfetch_dataset\u001b[0;34m(self, dataset, method, dry_run)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mcmd_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             util.run_command(['ncrcat']+chunks+[dataset.local_resource], \n\u001b[0;32m--> 407\u001b[0;31m                 cwd=dataset.nohash_tempdir)\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;31m# temp files cleaned up by data_manager.tearDown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local2/home/MDTF/MDTF-diagnostics/src/util.pyc\u001b[0m in \u001b[0;36mrun_command\u001b[0;34m(command, env, cwd)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         raise subprocess.CalledProcessError(\n\u001b[0;32m--> 474\u001b[0;31m             returncode=proc.returncode, cmd=' '.join(command), output=stderr)\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'\\0'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'ncrcat atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "for var in dm.iter_vars():\n",
    "    dm.fetch_dataset(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? ncrcat: ERROR Invalid response.\n",
      "ncrcat: /local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc exists---`e'xit, `o'verwrite (i.e., clobber existing file), or `a'ppend (i.e., replace duplicate variables in, and add metadata and new variables to, existing file) (e/o/a)? \n",
      "ncrcat: ERROR 11 failed attempts to obtain valid interactive input. Assuming non-interactive shell and exiting.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess32 as subprocess\n",
    "command = ['ncrcat', 'atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc', 'atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc', 'atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc', 'atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc', '/local2/home/MDTF/inputdata/model/CM4_historical/day/CM4_historical.pr.day.nc']\n",
    "cwd='/net2/Thomas.Jackson/tmp/MDTF_temp_-0x2d0ee0fca7b03bba/'\n",
    "proc = subprocess.Popen(\n",
    "    command, shell=False, cwd=cwd,\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "    universal_newlines=True, bufsize=0\n",
    ")\n",
    "(stdout, stderr) = proc.communicate()\n",
    "print stdout\n",
    "print stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess32 as subprocess\n",
    "files = ['atmos_cmip_2deg_daily_2D.19700101-19741231.pr.nc', 'atmos_cmip_2deg_daily_2D.19750101-19791231.pr.nc', 'atmos_cmip_2deg_daily_2D.19800101-19841231.pr.nc', 'atmos_cmip_2deg_daily_2D.19850101-19891231.pr.nc']\n",
    "command = ['ncrcat']+files+['/local2/home/MDTF/test2.nc']\n",
    "cwd='/net2/Thomas.Jackson/tmp/MDTF_temp_-0x2d0ee0fca7b03bba/'\n",
    "proc = subprocess.Popen(\n",
    "    command, shell=False, cwd=cwd,\n",
    "    stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "    universal_newlines=True, bufsize=0\n",
    ")\n",
    "(stdout, stderr) = proc.communicate()\n",
    "print stdout\n",
    "print stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.PathManager()._reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [{'a':[1,2], 'b':[5]}, {'a':[7,8]}]\n",
    "print [d['a'] for d in foo]\n",
    "print list(*(d['a'] for d in foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [{'a':[1,2], 'b':[5]}, {'a':[7,8]}]\n",
    "def iter_foo():\n",
    "    for d in foo: yield d\n",
    "def iter_foo2():\n",
    "    for d in foo: yield d['a'][0]\n",
    "def iter_foo3():\n",
    "    for d in foo: yield (d['a'][0] == 7)\n",
    "for d in iter_foo():\n",
    "    d['c'] = [69]\n",
    "print foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(iter_foo3())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print set(iter_foo2())\n",
    "# print len(iter_foo())\n",
    "for i,d in enumerate(iter_foo()):\n",
    "    print i, d['a']\n",
    "print itertools.count(iter_foo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goo = (d['a'] for d in foo)\n",
    "for g in goo:\n",
    "    print g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = [[],[1,2],[],[3,4]]\n",
    "print list(itertools.ifilter(None, foo))\n",
    "print filter(None, foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print files[0].remote_resource[0].file\n",
    "print files[0].remote_resource[1].file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_to_fetch = []\n",
    "ds_list = [d for d in ds.remote_resource if (d.component in cmpts)]\n",
    "# take longest chunk frequency (revisit?)\n",
    "chunk_freq = max({d.chunk_freq for d in ds_list})\n",
    "ds.remote_resource = [d for d in ds_list if (d.chunk_freq == chunk_freq)]\n",
    "assert ds.remote_resource # shouldn't have eliminated everything\n",
    "files_to_fetch.extend(ds.remote_resource)\n",
    "print files_to_fetch\n",
    "for f in files_to_fetch:\n",
    "    f.local_resource = dm.local_path(f)\n",
    "foo2 = [f for f in set(files_to_fetch) if not dm.local_data_is_current(f)]\n",
    "print foo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## junk below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.find_files(test_dir, '*/ts/daily/*.rlut.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files_to_fetch:\n",
    "    print f.remote_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempfile.tempdir = os.getcwd()\n",
    "foo1 = tempfile.mkdtemp(prefix='MDTF_temp_')\n",
    "print foo1\n",
    "os.rmdir(foo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print tempfile.tempdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ds.__hash__()\n",
    "print hex(ds.__hash__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_find(root_dir, dataset):\n",
    "    cmpts = [d for d in os.listdir(root_dir) if not d.startswith('.')]\n",
    "    candidates = []\n",
    "    query = '*.{}.nc'.format(dataset.name_in_model)\n",
    "    for rp1 in cmpts:\n",
    "        rp2 = os.path.join(rp1, 'ts', dataset.date_freq.format_frepp())\n",
    "        ap2 = os.path.join(root_dir, rp2)\n",
    "        if os.path.exists(ap2):\n",
    "            chunk_freqs = [d for d in os.listdir(ap2) if not d.startswith('.')]\n",
    "            for rp3 in chunk_freqs:\n",
    "                ap3 = os.path.join(ap2, rp3)\n",
    "                print ap3\n",
    "                paths = util.run_command([\n",
    "                    'find', ap3, '-name', query, '-print','-quit'\n",
    "                ])\n",
    "                if paths:\n",
    "                    print 'GOOD'\n",
    "                    candidates.append(ap3)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_find(test_dir, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/archive/oar.gfdl.cmip6/CM4/warsaw_201710_om4_v1.0.1/CM4_historical/gfdl.ncrc4-intel16-prod-openmp/pp/atmos_cmip_2deg_daily_2D/ts/daily/35yr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def query_dataset2(dataset, root_dir):\n",
    "        \"\"\"Return set of candidate directories for data files.\n",
    "        \"\"\"\n",
    "        if 'component' in dataset:\n",
    "            cmpts = [dataset.component]\n",
    "        else:\n",
    "            cmpts = [d for d in os.listdir(root_dir) if not d.startswith('.')]\n",
    "        candidate_dirs = []\n",
    "        suffix_query = '.{}.nc'.format(dataset.name_in_model)\n",
    "        for component in cmpts:\n",
    "            subdir_rel = os.path.join(component, 'ts', dataset.date_freq.format_frepp())\n",
    "            subdir_abs = os.path.join(root_dir, subdir_rel)\n",
    "            if not os.path.exists(subdir_abs):\n",
    "                continue\n",
    "            chunk_freqs = [d for d in os.listdir(subdir_abs) if not d.startswith('.')]\n",
    "            for freq in chunk_freqs:\n",
    "                paths = util.run_command([\n",
    "                    'find', os.path.join(subdir_abs, freq), '-name', '*'+suffix_query, '-print', '-quit'\n",
    "                ])\n",
    "                if paths:\n",
    "                    candidate_dirs.append(os.path.join(subdir_rel, freq))\n",
    "        if not candidate_dirs:\n",
    "            raise DataQueryFailure(dataset, 'No files found in {}'.format(root_dir))\n",
    "\n",
    "        for d in candidate_dirs:\n",
    "            files = [dm.parse_pp_path(f) for f in os.listdir(os.path.join(root_dir,d)) \\\n",
    "                if f.endswith(suffix_query)]\n",
    "            try:\n",
    "                remote_range = datelabel.DateRange([ds.date_range for ds in files])\n",
    "            except ValueError:\n",
    "                # Something's messed up with remote files if we get here\n",
    "                # should probably log an error\n",
    "                continue\n",
    "            if remote_range.contains(dataset.date_range):\n",
    "                dataset.remote_resource.extend(\n",
    "                    [ds for ds in files if (ds.date_range in dataset.date_range)]\n",
    "                )\n",
    "        if not dataset.remote_resource:\n",
    "            raise DataQueryFailure(dataset, \n",
    "                \"Couldn't cover date range {} with files in {}\".format(\n",
    "                    dataset.date_range, root_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset2(ds, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
